{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all of the features that have very similar distributions between the two types of transactions.\n",
    "df = df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential([\n",
    "    Dense(units=16, kernel_initializer='uniform', input_dim=19, activation='relu'),\n",
    "    Dense(units=18, kernel_initializer='uniform', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(20, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(24, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, Y_train, batch_size=15, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('\\nAnd the Score is ', score[1] * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [node.op.name for node in clf.inputs]\n",
    "output_nodes = [node.op.name for node in clf.outputs]\n",
    "\n",
    "print('input nodes => ' + str(input_nodes))\n",
    "print('output nodes => ' + str(output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "MODEL_PATH = './output/'\n",
    "MODEL_NAME = 'tensorflowModel'\n",
    "OPTIMISED_MODEL_PATH = '../src/main/resources/models/'\n",
    "OPTIMISED_MODEL_NAME = 'optimised_' + MODEL_NAME + '.pb'\n",
    "OPTIMISED_MODEL_TXT_NAME = 'optimised_' + MODEL_NAME + '.pbtxt'\n",
    "\n",
    "checkpoint_path = MODEL_PATH + MODEL_NAME + '.ckpt'\n",
    "model_frozen_path = MODEL_PATH + 'frozen_' + MODEL_NAME + '.pb'\n",
    "\n",
    "sess = keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save produced model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = saver.save(sess, checkpoint_path)\n",
    "print (\"Saved model at \", save_path)\n",
    "\n",
    "graph_path = tf.train.write_graph(sess.graph_def, MODEL_PATH, MODEL_NAME + \".pb\", as_text=True)\n",
    "print (\"Saved graph at :\", graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now freeze the graph (put variables into graph)\n",
    "\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = False\n",
    "output_node_names = ', '.join(output_nodes)\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "clear_devices = True\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(graph_path, input_saver_def_path,\n",
    "                         input_binary, save_path, output_node_names,\n",
    "                         restore_op_name, filename_tensor_name,\n",
    "                         model_frozen_path, clear_devices, \"\")\n",
    "\n",
    "print (\"Model is frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing graph\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(model_frozen_path, \"rb\") as f:\n",
    "   data = f.read()\n",
    "   input_graph_def.ParseFromString(data)\n",
    "\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "   input_graph_def,\n",
    "   input_nodes,      # an array of the input node(s)\n",
    "   output_nodes,      # an array of output nodes\n",
    "   tf.float32.as_datatype_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.write_graph(output_graph_def, OPTIMISED_MODEL_PATH, OPTIMISED_MODEL_NAME, as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.write_graph(output_graph_def, MODEL_PATH, OPTIMISED_MODEL_TXT_NAME, as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
